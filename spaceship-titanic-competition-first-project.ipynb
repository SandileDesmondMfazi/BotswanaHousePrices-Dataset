{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-10-02T17:21:21.642489Z","iopub.execute_input":"2023-10-02T17:21:21.643082Z","iopub.status.idle":"2023-10-02T17:21:22.091356Z","shell.execute_reply.started":"2023-10-02T17:21:21.643052Z","shell.execute_reply":"2023-10-02T17:21:22.090158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Binary Classification on Titanic Spaceship Dataset\n\n### Importing Libraries","metadata":{}},{"cell_type":"code","source":"import ydata_profiling as pp\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport missingno as msno\nfrom scipy import stats\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n%matplotlib inline\nsns.set(style=\"darkgrid\",font_scale=1.5)\npd.set_option(\"display.max.rows\",None)\npd.set_option(\"display.max.columns\",None)\n\n#from sklearn.svm import SVC\n#from sklearn.naive_bayes import GaussianNB\n#from sklearn.linear_model import LogisticRegression\n#from sklearn.neighbors import KNeighborsClassifier\n#from sklearn.tree import DecisionTreeClassifier\n#from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, StackingClassifier\n#from xgboost import XGBClassifier\n#from catboost import CatBoostClassifier\n#from lightgbm import LGBMClassifier\nfrom sklearn.neural_network import MLPClassifier\n\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\nfrom sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, confusion_matrix\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler, MinMaxScaler\n\nfrom imblearn.over_sampling import SMOTE","metadata":{"execution":{"iopub.status.busy":"2023-10-02T17:21:22.093233Z","iopub.execute_input":"2023-10-02T17:21:22.093799Z","iopub.status.idle":"2023-10-02T17:21:23.581169Z","shell.execute_reply.started":"2023-10-02T17:21:22.093762Z","shell.execute_reply":"2023-10-02T17:21:23.580087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Loading the Datasets","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv(\"/kaggle/input/spaceship-titanic/train.csv\")\ntest_df = pd.read_csv(\"/kaggle/input/spaceship-titanic/test.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-10-02T17:21:23.582565Z","iopub.execute_input":"2023-10-02T17:21:23.583103Z","iopub.status.idle":"2023-10-02T17:21:23.647724Z","shell.execute_reply.started":"2023-10-02T17:21:23.583071Z","shell.execute_reply":"2023-10-02T17:21:23.645942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Understanding","metadata":{}},{"cell_type":"code","source":"# Taking a look at the Dimensions of the Datasets\nprint(\"train_df shape is: \",train_df.shape)\nprint(\"testing_df shape is: \",test_df.shape)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T17:21:23.650871Z","iopub.execute_input":"2023-10-02T17:21:23.651284Z","iopub.status.idle":"2023-10-02T17:21:23.656618Z","shell.execute_reply.started":"2023-10-02T17:21:23.651251Z","shell.execute_reply":"2023-10-02T17:21:23.655707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Taking a look at the datatypes on each dataset\nprint(\"Training Dataset Feature Datatypes:\")\nprint(train_df.dtypes)\nprint(\"\\n\"+\"-\"*35)\nprint(\"\\nTesting Dataset Feature Datatypes:\")\nprint(test_df.dtypes)\nprint(\"\\n\"+\"-\"*35)\nprint(\"\\nTraining Dataset info:\")\nprint(train_df.info())","metadata":{"execution":{"iopub.status.busy":"2023-10-02T17:21:23.657693Z","iopub.execute_input":"2023-10-02T17:21:23.658721Z","iopub.status.idle":"2023-10-02T17:21:23.686027Z","shell.execute_reply.started":"2023-10-02T17:21:23.658687Z","shell.execute_reply":"2023-10-02T17:21:23.684806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Taking a sneak peek at the training dataset\nprint(\"Training Dataset\")\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-02T17:21:23.687869Z","iopub.execute_input":"2023-10-02T17:21:23.688204Z","iopub.status.idle":"2023-10-02T17:21:23.715283Z","shell.execute_reply.started":"2023-10-02T17:21:23.688176Z","shell.execute_reply":"2023-10-02T17:21:23.714092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Taking another sneak peek at the testing dataset\nprint(\"Testing Dataset\")\ntest_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-02T17:21:23.716900Z","iopub.execute_input":"2023-10-02T17:21:23.717220Z","iopub.status.idle":"2023-10-02T17:21:23.737120Z","shell.execute_reply.started":"2023-10-02T17:21:23.717192Z","shell.execute_reply":"2023-10-02T17:21:23.735858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#checking both datasets for duplicates\nprint(f\"{train_df.duplicated().sum()} duplicates in the Training Dataset\")\nprint(f\"{test_df.duplicated().sum()} duplicates in the Testing Dataset\")","metadata":{"execution":{"iopub.status.busy":"2023-10-02T17:21:23.738726Z","iopub.execute_input":"2023-10-02T17:21:23.739724Z","iopub.status.idle":"2023-10-02T17:21:23.772280Z","shell.execute_reply.started":"2023-10-02T17:21:23.739687Z","shell.execute_reply":"2023-10-02T17:21:23.771422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking the Missing values on each feature in the Training Dataset\nMissing_Values = (train_df.isnull().sum()[train_df.isnull().sum()>0]).to_frame().rename(columns={0:\"Number of Missing values\"})\nMissing_Values[\"Number of Values\"] = train_df.count()\nMissing_Values[\"% of Missing Values\"] = round((100*train_df.isnull().sum()[train_df.isnull().sum()>0]/len(train_df)),2)\nMissing_Values","metadata":{"execution":{"iopub.status.busy":"2023-10-02T17:21:23.773538Z","iopub.execute_input":"2023-10-02T17:21:23.774074Z","iopub.status.idle":"2023-10-02T17:21:23.811249Z","shell.execute_reply.started":"2023-10-02T17:21:23.774043Z","shell.execute_reply":"2023-10-02T17:21:23.810119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking the Missing values on each feature in the Testing Dataset\nMissing_Values = (test_df.isnull().sum()[test_df.isnull().sum()>0]).to_frame().rename(columns={0:\"Number of Missing values\"})\nMissing_Values[\"Number of Values\"] = test_df.count()\nMissing_Values[\"% of Missing Values\"] = round((100*test_df.isnull().sum()[test_df.isnull().sum()>0]/len(test_df)),2)\nMissing_Values","metadata":{"execution":{"iopub.status.busy":"2023-10-02T17:21:23.814303Z","iopub.execute_input":"2023-10-02T17:21:23.814998Z","iopub.status.idle":"2023-10-02T17:21:23.843478Z","shell.execute_reply.started":"2023-10-02T17:21:23.814966Z","shell.execute_reply":"2023-10-02T17:21:23.842114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## EDA using Pandas Profiling","metadata":{}},{"cell_type":"code","source":"pp.ProfileReport(train_df)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T17:21:23.845079Z","iopub.execute_input":"2023-10-02T17:21:23.845881Z","iopub.status.idle":"2023-10-02T17:21:54.947714Z","shell.execute_reply.started":"2023-10-02T17:21:23.845835Z","shell.execute_reply":"2023-10-02T17:21:54.946846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Feature Engineering","metadata":{}},{"cell_type":"code","source":"# Creating a function that creates New Features using the \"PassengerId\" Feature\n\ndef passengerid_new_features(*dfs):\n    for df in dfs:\n        #Splitting Group and Member values from \"PassengerId\" feature.\n        df[\"Group\"] = df[\"PassengerId\"].apply(lambda x: x.split(\"_\")[0])\n        df[\"Member\"] =df[\"PassengerId\"].apply(lambda x: x.split(\"_\")[1])\n\n        #Grouping the \"Group\" feature with respect to \"member\" feature to check which group is travelling with how many members\n        x = df.groupby(\"Group\")[\"Member\"].count().sort_values()\n\n        #Creating a set of group values which are travelling with more than 1 members.\n        y = set(x[x>1].index)\n\n        #Creating a new feature \"Solo\" which will indicate whether the person is travelling solo or not.\n        df[\"Travelling_Solo\"] = df[\"Group\"].apply(lambda x: x not in y)\n\n        #Creating a new feature \"Group_size\" which will indicate each group number of members.\n        df[\"Group_Size\"]=0\n        for i in x.items():\n            df.loc[df[\"Group\"]==i[0],\"Group_Size\"]=i[1]","metadata":{"execution":{"iopub.status.busy":"2023-10-02T17:21:54.948760Z","iopub.execute_input":"2023-10-02T17:21:54.949872Z","iopub.status.idle":"2023-10-02T17:21:54.963330Z","shell.execute_reply.started":"2023-10-02T17:21:54.949823Z","shell.execute_reply":"2023-10-02T17:21:54.961014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Using the function created on both the training and testing datasets\n\npassengerid_new_features(train_df, test_df)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T17:21:54.966221Z","iopub.execute_input":"2023-10-02T17:21:54.968587Z","iopub.status.idle":"2023-10-02T17:22:04.684133Z","shell.execute_reply.started":"2023-10-02T17:21:54.968486Z","shell.execute_reply":"2023-10-02T17:22:04.682889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-02T17:22:04.685522Z","iopub.execute_input":"2023-10-02T17:22:04.685862Z","iopub.status.idle":"2023-10-02T17:22:04.710697Z","shell.execute_reply.started":"2023-10-02T17:22:04.685835Z","shell.execute_reply":"2023-10-02T17:22:04.709598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Dropping features \"Group\" and \"Member\" since they carry information we dont need at the moment\ntrain_df.drop(columns=[\"Group\",\"Member\"],inplace=True)\ntest_df.drop(columns=[\"Group\",\"Member\"],inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T17:22:04.712472Z","iopub.execute_input":"2023-10-02T17:22:04.712843Z","iopub.status.idle":"2023-10-02T17:22:04.722864Z","shell.execute_reply.started":"2023-10-02T17:22:04.712815Z","shell.execute_reply":"2023-10-02T17:22:04.721720Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating a function that creates New Features using the \"Cabin\" Feature\n\ndef cabin_new_feature(*dfs):\n    for df in dfs:\n        df[\"Cabin\"].fillna(\"np.nan/np.nan/np.nan\", inplace=True)\n        \n        df[\"Cabin_Deck\"] = df[\"Cabin\"].apply(lambda x: x.split(\"/\")[0])\n        df[\"Cabin_Number\"] = df[\"Cabin\"].apply(lambda x: x.split(\"/\")[1])\n        df[\"Cabin_Side\"] = df[\"Cabin\"].apply(lambda x: x.split(\"/\")[2])\n        \n        cols = [\"Cabin_Deck\", \"Cabin_Number\", \"Cabin_Side\"]\n        df[cols] = df[cols].replace(\"np.nan\", np.nan)\n        \n        df[\"Cabin_Deck\"].fillna(df[\"Cabin_Deck\"].mode()[0], inplace=True)\n        df[\"Cabin_Side\"].fillna(df[\"Cabin_Side\"].mode()[0], inplace=True)\n        df[\"Cabin_Number\"].fillna(df[\"Cabin_Number\"].median(), inplace=True)\n","metadata":{"execution":{"iopub.status.busy":"2023-10-02T17:22:04.724674Z","iopub.execute_input":"2023-10-02T17:22:04.725561Z","iopub.status.idle":"2023-10-02T17:22:04.735736Z","shell.execute_reply.started":"2023-10-02T17:22:04.725524Z","shell.execute_reply":"2023-10-02T17:22:04.734572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Now, we are using this function on both datasets\ncabin_new_feature(train_df, test_df)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T17:22:04.737175Z","iopub.execute_input":"2023-10-02T17:22:04.737736Z","iopub.status.idle":"2023-10-02T17:22:04.793194Z","shell.execute_reply.started":"2023-10-02T17:22:04.737705Z","shell.execute_reply":"2023-10-02T17:22:04.792222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-02T17:22:04.794529Z","iopub.execute_input":"2023-10-02T17:22:04.794872Z","iopub.status.idle":"2023-10-02T17:22:04.818561Z","shell.execute_reply.started":"2023-10-02T17:22:04.794844Z","shell.execute_reply":"2023-10-02T17:22:04.817274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating a function that creates a new Feature \"Cabin_Regions\" From \"Cabin_Number\"\n\ndef cabin_regions(*dfs):\n    for df in dfs:\n        df[\"Cabin_Region1\"] = df[\"Cabin_Number\"].astype(float) < 300\n        df[\"Cabin_Region2\"] = (df[\"Cabin_Number\"].astype(float) >= 300) & (df[\"Cabin_Number\"].astype(float) < 600)\n        df[\"Cabin_Region3\"] = (df[\"Cabin_Number\"].astype(float) >= 600) & (df[\"Cabin_Number\"].astype(float) < 900)\n        df[\"Cabin_Region4\"] = (df[\"Cabin_Number\"].astype(float) >= 900) & (df[\"Cabin_Number\"].astype(float) < 1200)\n        df[\"Cabin_Region5\"] = (df[\"Cabin_Number\"].astype(float) >= 1200) & (df[\"Cabin_Number\"].astype(float) < 1500)\n        df[\"Cabin_Region6\"] = df[\"Cabin_Number\"].astype(float) >= 1500","metadata":{"execution":{"iopub.status.busy":"2023-10-02T17:22:04.820275Z","iopub.execute_input":"2023-10-02T17:22:04.820851Z","iopub.status.idle":"2023-10-02T17:22:04.831991Z","shell.execute_reply.started":"2023-10-02T17:22:04.820809Z","shell.execute_reply":"2023-10-02T17:22:04.829982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Run the function on both datasets\ncabin_regions(train_df, test_df)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T17:22:04.834485Z","iopub.execute_input":"2023-10-02T17:22:04.836245Z","iopub.status.idle":"2023-10-02T17:22:04.881108Z","shell.execute_reply.started":"2023-10-02T17:22:04.836160Z","shell.execute_reply":"2023-10-02T17:22:04.879765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-02T17:22:04.882627Z","iopub.execute_input":"2023-10-02T17:22:04.883159Z","iopub.status.idle":"2023-10-02T17:22:04.919085Z","shell.execute_reply.started":"2023-10-02T17:22:04.883125Z","shell.execute_reply":"2023-10-02T17:22:04.917571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# The \"Cabin_Number\" Feature carries information we dont need anymore so we are going to drop it on both datasets\ntrain_df.drop(columns=[\"Cabin_Number\"],inplace=True)\ntest_df.drop(columns=[\"Cabin_Number\"],inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T17:22:04.921070Z","iopub.execute_input":"2023-10-02T17:22:04.921627Z","iopub.status.idle":"2023-10-02T17:22:04.935380Z","shell.execute_reply.started":"2023-10-02T17:22:04.921576Z","shell.execute_reply":"2023-10-02T17:22:04.933936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Creating a function that creates a new Feature \"Age_Group\" From \"Age\"\ndef age_group(*dfs):\n    for df in dfs:\n        bins = [0, 12, 18, 25, 32, 50, float('inf')]  # Define the age group bins\n        labels = [\"0-12\", \"12-18\", \"19-25\", \"26-32\", \"33-50\", \"50+\"]  # Labels for the age groups\n        \n        df[\"Age Group\"] = pd.cut(df[\"Age\"], bins=bins, labels=labels, right=False)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T17:22:04.937249Z","iopub.execute_input":"2023-10-02T17:22:04.938213Z","iopub.status.idle":"2023-10-02T17:22:04.944521Z","shell.execute_reply.started":"2023-10-02T17:22:04.938167Z","shell.execute_reply":"2023-10-02T17:22:04.943320Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"age_group(train_df, test_df)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T17:22:04.946531Z","iopub.execute_input":"2023-10-02T17:22:04.947087Z","iopub.status.idle":"2023-10-02T17:22:04.971025Z","shell.execute_reply.started":"2023-10-02T17:22:04.947053Z","shell.execute_reply":"2023-10-02T17:22:04.969284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-02T17:22:04.972666Z","iopub.execute_input":"2023-10-02T17:22:04.973468Z","iopub.status.idle":"2023-10-02T17:22:05.001323Z","shell.execute_reply.started":"2023-10-02T17:22:04.973422Z","shell.execute_reply":"2023-10-02T17:22:04.999949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating New Features Using All Expenditude Features\n\nexp_cols = [\"RoomService\",\"FoodCourt\",\"ShoppingMall\",\"Spa\",\"VRDeck\"]\n\ndef new_exp_features(*dfs):\n    for df in dfs:\n        df[\"Total Expenditure\"] = df[exp_cols].sum(axis=1)\n        df[\"No Spending\"] = (df[\"Total Expenditure\"]==0)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T17:22:05.002652Z","iopub.execute_input":"2023-10-02T17:22:05.002993Z","iopub.status.idle":"2023-10-02T17:22:05.014628Z","shell.execute_reply.started":"2023-10-02T17:22:05.002965Z","shell.execute_reply":"2023-10-02T17:22:05.013280Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_exp_features(train_df, test_df)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T17:22:05.016047Z","iopub.execute_input":"2023-10-02T17:22:05.016661Z","iopub.status.idle":"2023-10-02T17:22:05.034738Z","shell.execute_reply.started":"2023-10-02T17:22:05.016630Z","shell.execute_reply":"2023-10-02T17:22:05.033607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-02T17:22:05.042570Z","iopub.execute_input":"2023-10-02T17:22:05.043193Z","iopub.status.idle":"2023-10-02T17:22:05.076649Z","shell.execute_reply.started":"2023-10-02T17:22:05.043152Z","shell.execute_reply":"2023-10-02T17:22:05.075506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Generating some statistical information from Total Expenditue feature\n\nstat_cols = [\"PassengerId\", \"Total Expenditure\", \"No Spending\"]\nstat_df = train_df[stat_cols]\n\npp.ProfileReport(stat_df)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T17:22:05.078058Z","iopub.execute_input":"2023-10-02T17:22:05.079424Z","iopub.status.idle":"2023-10-02T17:22:09.757183Z","shell.execute_reply.started":"2023-10-02T17:22:05.079335Z","shell.execute_reply":"2023-10-02T17:22:09.756090Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Using the measures of central tendency to categorise each expense\n\ndef expenditure_category(*dfs):\n    for df in dfs:\n        bins = [-1, 0, 716, 1441, float('inf')]  # Define the expenditure category bins using Q1, Median, and Q3\n        labels = [\"No Expense\", \"Low Expense\", \"Medium Expense\", \"High Expense\"]  # Labels for the categories\n        \n        df[\"Expenditure Category\"] = pd.cut(df[\"Total Expenditure\"], bins=bins, labels=labels, right=False)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T17:22:09.758298Z","iopub.execute_input":"2023-10-02T17:22:09.759582Z","iopub.status.idle":"2023-10-02T17:22:09.766712Z","shell.execute_reply.started":"2023-10-02T17:22:09.759530Z","shell.execute_reply":"2023-10-02T17:22:09.764859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"expenditure_category(train_df, test_df)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T17:22:09.768304Z","iopub.execute_input":"2023-10-02T17:22:09.768750Z","iopub.status.idle":"2023-10-02T17:22:09.790658Z","shell.execute_reply.started":"2023-10-02T17:22:09.768719Z","shell.execute_reply":"2023-10-02T17:22:09.789431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-02T17:22:09.792502Z","iopub.execute_input":"2023-10-02T17:22:09.793915Z","iopub.status.idle":"2023-10-02T17:22:09.828323Z","shell.execute_reply.started":"2023-10-02T17:22:09.793864Z","shell.execute_reply":"2023-10-02T17:22:09.827068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data PreProcessing\n\n### Visualizing Missing Numbers","metadata":{}},{"cell_type":"code","source":"msno.bar(train_df,color=\"C3\",fontsize=22)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-02T17:22:09.830138Z","iopub.execute_input":"2023-10-02T17:22:09.830930Z","iopub.status.idle":"2023-10-02T17:22:12.278000Z","shell.execute_reply.started":"2023-10-02T17:22:09.830881Z","shell.execute_reply":"2023-10-02T17:22:12.276820Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Handling Missing Values","metadata":{}},{"cell_type":"code","source":"# Selecting the categorical features and excluding the \"Transported\" Feature\ncategorical_cols = train_df.select_dtypes(include=[\"object\",\"bool\"]).columns.tolist()\ncategorical_cols.remove(\"Transported\")\nnum_cols = train_df.select_dtypes(include=[\"int\",\"float\"]).columns.tolist()\n\nprint(\"Categorical Columns:\",categorical_cols)\nprint(\"\\n\",\"-\"*35)\nprint(\"\\nNumerical Columns:\",num_cols)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T17:22:12.279650Z","iopub.execute_input":"2023-10-02T17:22:12.280285Z","iopub.status.idle":"2023-10-02T17:22:12.294312Z","shell.execute_reply.started":"2023-10-02T17:22:12.280247Z","shell.execute_reply":"2023-10-02T17:22:12.293034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Using Simple Imputer Library to Fill Missing Values\nimputer1 = SimpleImputer(strategy=\"most_frequent\")     ##To fill Categorical Features.\nimputer2 = SimpleImputer(strategy=\"median\")            ##To fill numeircal features.","metadata":{"execution":{"iopub.status.busy":"2023-10-02T17:22:12.296146Z","iopub.execute_input":"2023-10-02T17:22:12.296934Z","iopub.status.idle":"2023-10-02T17:22:12.303853Z","shell.execute_reply.started":"2023-10-02T17:22:12.296885Z","shell.execute_reply":"2023-10-02T17:22:12.302186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def fill_missingno(*dfs):\n    for df in dfs:\n        df[categorical_cols] = imputer1.fit_transform(df[categorical_cols])\n        df[num_cols] = imputer2.fit_transform(df[num_cols])","metadata":{"execution":{"iopub.status.busy":"2023-10-02T17:22:12.305713Z","iopub.execute_input":"2023-10-02T17:22:12.306943Z","iopub.status.idle":"2023-10-02T17:22:12.322689Z","shell.execute_reply.started":"2023-10-02T17:22:12.306892Z","shell.execute_reply":"2023-10-02T17:22:12.321511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Running the Missing Values handling function\nfill_missingno(train_df, test_df)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T17:22:12.324480Z","iopub.execute_input":"2023-10-02T17:22:12.325301Z","iopub.status.idle":"2023-10-02T17:22:12.432017Z","shell.execute_reply.started":"2023-10-02T17:22:12.325261Z","shell.execute_reply":"2023-10-02T17:22:12.430877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Visualizing, and checking if we still have missing values","metadata":{}},{"cell_type":"code","source":"msno.bar(train_df,color=\"C3\",fontsize=22)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-02T17:22:12.433800Z","iopub.execute_input":"2023-10-02T17:22:12.434591Z","iopub.status.idle":"2023-10-02T17:22:14.614786Z","shell.execute_reply.started":"2023-10-02T17:22:12.434546Z","shell.execute_reply":"2023-10-02T17:22:14.613268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As you can see we still have missing values on the \"Age Group\" feature we created, looks like we have have to re-run the age-group function on this dataset. ","metadata":{}},{"cell_type":"code","source":"# Drop the Age_Group feature\ntrain_df.drop(columns=[\"Age Group\"],inplace=True)\ntest_df.drop(columns=[\"Age Group\"],inplace=True)\n\n#Re-run the Age Group function\nage_group(train_df, test_df)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T17:22:14.616584Z","iopub.execute_input":"2023-10-02T17:22:14.617040Z","iopub.status.idle":"2023-10-02T17:22:14.642101Z","shell.execute_reply.started":"2023-10-02T17:22:14.616998Z","shell.execute_reply":"2023-10-02T17:22:14.640544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Checking again for missing values\nmsno.bar(train_df,color=\"C3\",fontsize=22)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-02T17:22:14.643572Z","iopub.execute_input":"2023-10-02T17:22:14.644155Z","iopub.status.idle":"2023-10-02T17:22:16.778971Z","shell.execute_reply.started":"2023-10-02T17:22:14.644123Z","shell.execute_reply":"2023-10-02T17:22:16.777777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Looks we have handled all missing values\n\n### Checking for Duplicates in Data","metadata":{}},{"cell_type":"code","source":"print(\"In training data is: \",train_df.duplicated().sum())\nprint(\"In testing data is: \",test_df.duplicated().sum())","metadata":{"execution":{"iopub.status.busy":"2023-10-02T17:22:16.780265Z","iopub.execute_input":"2023-10-02T17:22:16.780633Z","iopub.status.idle":"2023-10-02T17:22:16.819970Z","shell.execute_reply.started":"2023-10-02T17:22:16.780603Z","shell.execute_reply":"2023-10-02T17:22:16.818311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pp.ProfileReport(train_df)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T17:22:16.821380Z","iopub.execute_input":"2023-10-02T17:22:16.822229Z","iopub.status.idle":"2023-10-02T17:22:56.009447Z","shell.execute_reply.started":"2023-10-02T17:22:16.822195Z","shell.execute_reply":"2023-10-02T17:22:56.007949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Based on the summary we got from Pandas_Profiling\n\n**PassengerId** has a high cardinality: 8693 distinct values\t***High cardinality***\n\n**Cabin** has a high cardinality: 6561 distinct values\t***High cardinality***\n\n**Name** has a high cardinality: 8473 distinct values\t***High cardinality***","metadata":{}},{"cell_type":"code","source":"# Dropping Categorical Features with High Cardinality\n\nTest_PassengerId = test_df[[\"PassengerId\"]]#Saving the passengerId feature from test data because we need this for submitting our predictions on kaggle\n\ncols = [\"PassengerId\",\"Cabin\",\"Name\"]\ntrain_df.drop(columns =cols, inplace=True)\ntest_df.drop(columns=cols, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T17:22:56.011738Z","iopub.execute_input":"2023-10-02T17:22:56.012716Z","iopub.status.idle":"2023-10-02T17:22:56.035501Z","shell.execute_reply.started":"2023-10-02T17:22:56.012657Z","shell.execute_reply":"2023-10-02T17:22:56.034436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Applying Log Transformation on Expenditure Features, which helps with handling the skewed dataset\n\ncols = ['RoomService','FoodCourt','ShoppingMall','Spa','VRDeck','Total Expenditure']\n\nfor value in cols:\n    train_df[value] = np.log(1+train_df[value])\n    test_df[value]=np.log(1+test_df[value])","metadata":{"execution":{"iopub.status.busy":"2023-10-02T17:22:56.037054Z","iopub.execute_input":"2023-10-02T17:22:56.037721Z","iopub.status.idle":"2023-10-02T17:22:56.065720Z","shell.execute_reply.started":"2023-10-02T17:22:56.037683Z","shell.execute_reply":"2023-10-02T17:22:56.064428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Changing Data-Type to Boolean\n\ncols = [\"CryoSleep\",\"VIP\",\"Travelling_Solo\",\"No Spending\",\"Cabin_Region1\",\"Cabin_Region2\",\"Cabin_Region3\",\"Cabin_Region4\",\n       \"Cabin_Region5\",\"Cabin_Region6\"]\n\ntrain_df[cols] = train_df[cols].astype(bool)\ntest_df[cols] = test_df[cols].astype(bool)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T17:22:56.067148Z","iopub.execute_input":"2023-10-02T17:22:56.067516Z","iopub.status.idle":"2023-10-02T17:22:56.090963Z","shell.execute_reply.started":"2023-10-02T17:22:56.067487Z","shell.execute_reply":"2023-10-02T17:22:56.089732Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Feature Encoding","metadata":{}},{"cell_type":"code","source":"nominal_cat_cols = [\"HomePlanet\",\"Destination\"]\nordinal_cat_cols = [\"CryoSleep\",\"VIP\",\"Travelling_Solo\",\"Cabin_Deck\",\"Cabin_Side\",\"Cabin_Region1\",\"Cabin_Region2\",\n                    \"Cabin_Region3\",\"Cabin_Region4\",\"Cabin_Region5\",\"Cabin_Region6\",\"Age Group\",\"No Spending\",\n                    \"Expenditure Category\"]","metadata":{"execution":{"iopub.status.busy":"2023-10-02T17:22:56.093062Z","iopub.execute_input":"2023-10-02T17:22:56.093735Z","iopub.status.idle":"2023-10-02T17:22:56.102536Z","shell.execute_reply.started":"2023-10-02T17:22:56.093677Z","shell.execute_reply":"2023-10-02T17:22:56.101327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Label Encoding\nenc = LabelEncoder()\ntrain_df[ordinal_cat_cols] = train_df[ordinal_cat_cols].apply(enc.fit_transform)\ntest_df[ordinal_cat_cols] = test_df[ordinal_cat_cols].apply(enc.fit_transform)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T17:22:56.104178Z","iopub.execute_input":"2023-10-02T17:22:56.104642Z","iopub.status.idle":"2023-10-02T17:22:56.158269Z","shell.execute_reply.started":"2023-10-02T17:22:56.104610Z","shell.execute_reply":"2023-10-02T17:22:56.156823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# One Hot Encoding\ntrain_df = pd.get_dummies(train_df,columns=nominal_cat_cols)\ntest_df = pd.get_dummies(test_df,columns=nominal_cat_cols)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T17:22:56.159871Z","iopub.execute_input":"2023-10-02T17:22:56.160583Z","iopub.status.idle":"2023-10-02T17:22:56.187279Z","shell.execute_reply.started":"2023-10-02T17:22:56.160547Z","shell.execute_reply":"2023-10-02T17:22:56.185283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.columns","metadata":{"execution":{"iopub.status.busy":"2023-10-02T17:22:56.189298Z","iopub.execute_input":"2023-10-02T17:22:56.190604Z","iopub.status.idle":"2023-10-02T17:22:56.198740Z","shell.execute_reply.started":"2023-10-02T17:22:56.190553Z","shell.execute_reply":"2023-10-02T17:22:56.197663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Still have one feature Transported left for encoding in training dataset\ntrain_df[\"Transported\"].replace({False:0,True:1},inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T17:22:56.200905Z","iopub.execute_input":"2023-10-02T17:22:56.201791Z","iopub.status.idle":"2023-10-02T17:22:56.218046Z","shell.execute_reply.started":"2023-10-02T17:22:56.201752Z","shell.execute_reply":"2023-10-02T17:22:56.216392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Selecting Features & Labels For Model Training.","metadata":{}},{"cell_type":"code","source":"X = train_df.drop(columns=[\"Transported\"])\ny = train_df[[\"Transported\"]]","metadata":{"execution":{"iopub.status.busy":"2023-10-02T17:22:56.221096Z","iopub.execute_input":"2023-10-02T17:22:56.221730Z","iopub.status.idle":"2023-10-02T17:22:56.233717Z","shell.execute_reply.started":"2023-10-02T17:22:56.221694Z","shell.execute_reply":"2023-10-02T17:22:56.232225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Feature Scaling","metadata":{}},{"cell_type":"code","source":"scaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\ntest_df_scaled = scaler.fit_transform(test_df)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T17:22:56.235187Z","iopub.execute_input":"2023-10-02T17:22:56.236315Z","iopub.status.idle":"2023-10-02T17:22:56.285963Z","shell.execute_reply.started":"2023-10-02T17:22:56.236249Z","shell.execute_reply":"2023-10-02T17:22:56.284746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Splitting Data For Model w/ Unscaled Data","metadata":{}},{"cell_type":"code","source":"x_train,x_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=0)\nprint(x_train.shape, y_train.shape)\nprint(x_test.shape,y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T17:22:56.287623Z","iopub.execute_input":"2023-10-02T17:22:56.287964Z","iopub.status.idle":"2023-10-02T17:22:56.306864Z","shell.execute_reply.started":"2023-10-02T17:22:56.287937Z","shell.execute_reply":"2023-10-02T17:22:56.304375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Splitting Data for Model w/ Scaled Data","metadata":{}},{"cell_type":"code","source":"x_train1, x_test1, y_train1, y_test1 = train_test_split(X_scaled,y,test_size=0.2,random_state=0)\nprint(x_train1.shape, y_train1.shape)\nprint(x_test1.shape, y_test1.shape)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T17:22:56.308709Z","iopub.execute_input":"2023-10-02T17:22:56.309072Z","iopub.status.idle":"2023-10-02T17:22:56.319574Z","shell.execute_reply.started":"2023-10-02T17:22:56.309046Z","shell.execute_reply":"2023-10-02T17:22:56.318092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model Building For Scaled Data","metadata":{}},{"cell_type":"code","source":"training_score = []\ntesting_score = []","metadata":{"execution":{"iopub.status.busy":"2023-10-02T17:22:56.322030Z","iopub.execute_input":"2023-10-02T17:22:56.322618Z","iopub.status.idle":"2023-10-02T17:22:56.328777Z","shell.execute_reply.started":"2023-10-02T17:22:56.322541Z","shell.execute_reply":"2023-10-02T17:22:56.327622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Model Building function\ndef model_prediction_S(model):\n    model.fit(x_train1,y_train1)\n    x_train_pred1 = model.predict(x_train1)\n    x_test_pred1 = model.predict(x_test1)\n    a = accuracy_score(y_train1,x_train_pred1)*100\n    b = accuracy_score(y_test1,x_test_pred1)*100\n    training_score.append(a)\n    testing_score.append(b)\n    \n    print(f\"Accuracy_Score of {model} model on Training Data is:\",a)\n    print(f\"Accuracy_Score of {model} model on Testing Data is:\",b)\n    print(\"\\n------------------------------------------------------------------------\")\n    print(f\"Precision Score of {model} model is:\",precision_score(y_test1,x_test_pred1))\n    print(f\"Recall Score of {model} model is:\",recall_score(y_test1,x_test_pred1))\n    print(f\"F1 Score of {model} model is:\",f1_score(y_test1,x_test_pred1))\n    print(\"\\n------------------------------------------------------------------------\")\n    print(f\"Confusion Matrix of {model} model is:\")\n    cm = confusion_matrix(y_test1,x_test_pred1)\n    plt.figure(figsize=(8,4))\n    sns.heatmap(cm,annot=True,fmt=\"g\",cmap=\"summer\")\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-02T19:11:49.155289Z","iopub.execute_input":"2023-10-02T19:11:49.155700Z","iopub.status.idle":"2023-10-02T19:11:49.165474Z","shell.execute_reply.started":"2023-10-02T19:11:49.155672Z","shell.execute_reply":"2023-10-02T19:11:49.164258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1. Multi-layer Perceptron Classifier Model","metadata":{}},{"cell_type":"code","source":"clf = MLPClassifier(\n    solver='adam',\n    learning_rate_init = 0.001,\n    alpha=1e-5,\n    hidden_layer_sizes=(100, 50),\n    activation='relu',\n    random_state=1,\n    batch_size = 32,\n    max_iter = 200,\n    early_stopping=True,\n    n_iter_no_change = 10,\n    learning_rate = 'adaptive'\n)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T18:22:45.295710Z","iopub.execute_input":"2023-10-02T18:22:45.296072Z","iopub.status.idle":"2023-10-02T18:22:45.301974Z","shell.execute_reply.started":"2023-10-02T18:22:45.296045Z","shell.execute_reply":"2023-10-02T18:22:45.300773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_prediction_S(clf)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T18:22:50.649756Z","iopub.execute_input":"2023-10-02T18:22:50.650851Z","iopub.status.idle":"2023-10-02T18:22:53.238960Z","shell.execute_reply.started":"2023-10-02T18:22:50.650804Z","shell.execute_reply":"2023-10-02T18:22:53.237787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Performing ***hyperparameter tuning*** using a technique called GridSearchCV","metadata":{}},{"cell_type":"code","source":"def model_prediction_with_tuning(model):\n    # Define the parameter grid for hyperparameter tuning\n    param_grid = {\n        'hidden_layer_sizes': [(100, 50), (200, 100), (50, 25)],\n        'alpha': [1e-6,1e-5, 1e-4, 1e-3],\n        'learning_rate_init': [0.001, 0.01, 0.1],\n        'batch_size': [32,64],\n        'early_stopping':[True],\n        'n_iter_no_change':[10,20]\n    }\n\n    # Initialize GridSearchCV\n    grid_search = GridSearchCV(\n        estimator=model,\n        param_grid=param_grid,\n        scoring='accuracy',\n        cv=5,\n        n_jobs=-1,\n    )\n    # Convert DataFrame to NumPy array\n    y_train1_np = np.array(y_train1)\n\n    # Fit the grid search to the training data\n    grid_search.fit(x_train1, y_train1_np.ravel())\n\n    # Retrieve the best hyperparameters and best model\n    best_params = grid_search.best_params_\n    best_model = grid_search.best_estimator_\n\n    # Use the best model for prediction\n    x_train_pred1 = best_model.predict(x_train1)\n    x_test_pred1 = best_model.predict(x_test1)\n\n    # Compute and store accuracy scores\n    a = accuracy_score(y_train1, x_train_pred1) * 100\n    b = accuracy_score(y_test1, x_test_pred1) * 100\n    training_score.append(a)\n    testing_score.append(b)\n\n    # Print results, including best hyperparameters\n    print(f\"Best hyperparameters: {best_params}\")\n    print(f\"Accuracy_Score of {best_model} model on Training Data is:\", a)\n    print(f\"Accuracy_Score of {best_model} model on Testing Data is:\", b)\n    # (print other metrics and confusion matrix)\n","metadata":{"execution":{"iopub.status.busy":"2023-10-02T18:23:57.828012Z","iopub.execute_input":"2023-10-02T18:23:57.828608Z","iopub.status.idle":"2023-10-02T18:23:57.839993Z","shell.execute_reply.started":"2023-10-02T18:23:57.828567Z","shell.execute_reply":"2023-10-02T18:23:57.838498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_prediction_with_tuning(clf)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T18:42:55.018945Z","iopub.execute_input":"2023-10-02T18:42:55.019375Z","iopub.status.idle":"2023-10-02T18:55:49.557691Z","shell.execute_reply.started":"2023-10-02T18:42:55.019319Z","shell.execute_reply":"2023-10-02T18:55:49.555612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model Building For Unscaled Data","metadata":{}},{"cell_type":"code","source":"# Model Building function x_train,x_test,y_train,y_test\ndef model_prediction_US(model):\n    model.fit(x_train,y_train)\n    x_train_pred = model.predict(x_train)\n    x_test_pred = model.predict(x_test)\n    a = accuracy_score(y_train,x_train_pred)*100\n    b = accuracy_score(y_test,x_test_pred)*100\n    training_score.append(a)\n    testing_score.append(b)\n    \n    print(f\"Accuracy_Score of {model} model on Training Data is:\",a)\n    print(f\"Accuracy_Score of {model} model on Testing Data is:\",b)\n    print(\"\\n------------------------------------------------------------------------\")\n    print(f\"Precision Score of {model} model is:\",precision_score(y_test,x_test_pred))\n    print(f\"Recall Score of {model} model is:\",recall_score(y_test,x_test_pred))\n    print(f\"F1 Score of {model} model is:\",f1_score(y_test,x_test_pred))\n    print(\"\\n------------------------------------------------------------------------\")\n    print(f\"Confusion Matrix of {model} model is:\")\n    cm = confusion_matrix(y_test,x_test_pred)\n    plt.figure(figsize=(8,4))\n    sns.heatmap(cm,annot=True,fmt=\"g\",cmap=\"summer\")\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-02T19:12:35.141552Z","iopub.execute_input":"2023-10-02T19:12:35.141917Z","iopub.status.idle":"2023-10-02T19:12:35.151215Z","shell.execute_reply.started":"2023-10-02T19:12:35.141890Z","shell.execute_reply":"2023-10-02T19:12:35.149770Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_prediction_US(clf)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T19:12:55.953235Z","iopub.execute_input":"2023-10-02T19:12:55.953629Z","iopub.status.idle":"2023-10-02T19:13:02.426195Z","shell.execute_reply.started":"2023-10-02T19:12:55.953599Z","shell.execute_reply":"2023-10-02T19:13:02.424524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Performing ***hyperparameter tuning*** using a technique called GridSearchCV","metadata":{}},{"cell_type":"code","source":"def model_prediction_with_tuning_US(model):\n    # Define the parameter grid for hyperparameter tuning\n    param_grid = {\n        'hidden_layer_sizes': [(100, 50), (200, 100), (50, 25)],\n        'alpha': [1e-6,1e-5, 1e-4, 1e-3],\n        'learning_rate_init': [0.001, 0.01, 0.1],\n        'batch_size': [32,64],\n        'early_stopping':[True],\n        'n_iter_no_change':[10,20]\n    }\n\n    # Initialize GridSearchCV\n    grid_search = GridSearchCV(\n        estimator=model,\n        param_grid=param_grid,\n        scoring='accuracy',\n        cv=5,\n        n_jobs=-1,\n    )\n    # Convert DataFrame to NumPy array\n    y_train_np = np.array(y_train)\n\n    # Fit the grid search to the training data\n    grid_search.fit(x_train, y_train_np.ravel())\n\n    # Retrieve the best hyperparameters and best model\n    best_params = grid_search.best_params_\n    best_model = grid_search.best_estimator_\n\n    # Use the best model for prediction\n    x_train_pred = best_model.predict(x_train)\n    x_test_pred = best_model.predict(x_test)\n\n    # Compute and store accuracy scores\n    a = accuracy_score(y_train, x_train_pred) * 100\n    b = accuracy_score(y_test, x_test_pred) * 100\n    training_score.append(a)\n    testing_score.append(b)\n\n    # Print results, including best hyperparameters\n    print(f\"Best hyperparameters: {best_params}\")\n    print(f\"Accuracy_Score of {best_model} model on Training Data is:\", a)\n    print(f\"Accuracy_Score of {best_model} model on Testing Data is:\", b)\n    # (print other metrics and confusion matrix)\n","metadata":{"execution":{"iopub.status.busy":"2023-10-02T19:18:00.951490Z","iopub.execute_input":"2023-10-02T19:18:00.951928Z","iopub.status.idle":"2023-10-02T19:18:00.961663Z","shell.execute_reply.started":"2023-10-02T19:18:00.951897Z","shell.execute_reply":"2023-10-02T19:18:00.960459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_prediction_with_tuning_US(clf)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T19:18:19.375533Z","iopub.execute_input":"2023-10-02T19:18:19.376082Z","iopub.status.idle":"2023-10-02T19:34:04.045522Z","shell.execute_reply.started":"2023-10-02T19:18:19.375932Z","shell.execute_reply":"2023-10-02T19:34:04.044029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission- Data Format","metadata":{}},{"cell_type":"code","source":"pred = clf.predict(test_df)\n\npred","metadata":{"execution":{"iopub.status.busy":"2023-10-02T19:38:20.781594Z","iopub.execute_input":"2023-10-02T19:38:20.781953Z","iopub.status.idle":"2023-10-02T19:38:20.809181Z","shell.execute_reply.started":"2023-10-02T19:38:20.781925Z","shell.execute_reply":"2023-10-02T19:38:20.807309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Test_PassengerId.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-02T19:36:22.356002Z","iopub.execute_input":"2023-10-02T19:36:22.356471Z","iopub.status.idle":"2023-10-02T19:36:22.370428Z","shell.execute_reply.started":"2023-10-02T19:36:22.356436Z","shell.execute_reply":"2023-10-02T19:36:22.369206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Test_PassengerId[\"Transported\"] = pred","metadata":{"execution":{"iopub.status.busy":"2023-10-02T19:39:01.994875Z","iopub.execute_input":"2023-10-02T19:39:01.996528Z","iopub.status.idle":"2023-10-02T19:39:02.002764Z","shell.execute_reply.started":"2023-10-02T19:39:01.996457Z","shell.execute_reply":"2023-10-02T19:39:02.001840Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Test_PassengerId.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Submission_Dataset = Test_PassengerId\nSubmission_Dataset.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-02T19:40:06.188684Z","iopub.execute_input":"2023-10-02T19:40:06.189614Z","iopub.status.idle":"2023-10-02T19:40:06.201306Z","shell.execute_reply.started":"2023-10-02T19:40:06.189565Z","shell.execute_reply":"2023-10-02T19:40:06.200192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Submission_Dataset[\"Transported\"].replace({1:True,0:False},inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T19:40:20.660855Z","iopub.execute_input":"2023-10-02T19:40:20.661208Z","iopub.status.idle":"2023-10-02T19:40:20.669911Z","shell.execute_reply.started":"2023-10-02T19:40:20.661183Z","shell.execute_reply":"2023-10-02T19:40:20.668694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Submission_Dataset.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-02T19:40:35.680587Z","iopub.execute_input":"2023-10-02T19:40:35.680938Z","iopub.status.idle":"2023-10-02T19:40:35.692088Z","shell.execute_reply.started":"2023-10-02T19:40:35.680911Z","shell.execute_reply":"2023-10-02T19:40:35.690483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Submission_Dataset.shape","metadata":{"execution":{"iopub.status.busy":"2023-10-02T19:40:54.041711Z","iopub.execute_input":"2023-10-02T19:40:54.042103Z","iopub.status.idle":"2023-10-02T19:40:54.049516Z","shell.execute_reply.started":"2023-10-02T19:40:54.042075Z","shell.execute_reply":"2023-10-02T19:40:54.047902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Submission_Dataset.to_csv(\"spaceship_prediction_DS_Project.csv\",index=False)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T19:41:24.549198Z","iopub.execute_input":"2023-10-02T19:41:24.550423Z","iopub.status.idle":"2023-10-02T19:41:24.566573Z","shell.execute_reply.started":"2023-10-02T19:41:24.550382Z","shell.execute_reply":"2023-10-02T19:41:24.565455Z"},"trusted":true},"execution_count":null,"outputs":[]}]}